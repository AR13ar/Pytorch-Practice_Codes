{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Xanthor-Aditya/Pytorch-Practice_Codes/blob/master/Cifar10-CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuVuhoVKqaid",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_cuda = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MX0yuoLOFPUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpW5URahFPFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtoUYg6EKokr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PKIWAHZGpgs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision.datasets as dsets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZEBJAr8GyEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sa9YPb_LG5fp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SB4MOPxQjIMU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_size = (3,32,32)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmZlL64Ht6bw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "number_of_filters1 = 16\n",
        "filter_size1 = 3\n",
        "number_of_filters2 = 32\n",
        "filter_size2 = 5\n",
        "padding = 1\n",
        "stride = 1\n",
        "hidden_size = 128\n",
        "num_classes = 10\n",
        "num_epochs = 20\n",
        "batch_size = 32\n",
        "learning_rate = 0.0001\n",
        "nn_input= 900"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYI24oDauFjz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "0e4df5a3-9999-41dd-9f30-be96fe8ce2fd"
      },
      "source": [
        "train_dataset = dsets.CIFAR10(root='./data',\n",
        "                           train=True,\n",
        "                           transform= transforms.ToTensor(),\n",
        "                           download=True)\n",
        "\n",
        "test_dataset = dsets.CIFAR10(root='./data',\n",
        "                           train=False,\n",
        "                           transform= transforms.ToTensor())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "170500096it [00:07, 23120539.88it/s]                               \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SynR9HamuRdl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeZa187Kukxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, number_of_filters1, filter_size1,stride, padding)\n",
        "    self.conv2 = nn.Conv2d(number_of_filters1, number_of_filters2, filter_size2, stride, padding)\n",
        "    self.bn1 = nn.BatchNorm2d(number_of_filters2)\n",
        "    #self.global_mxpool = nn.AvgPool2d(2,2)\n",
        "    self.fc1 = nn.Linear(nn_input*number_of_filters2, hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "  def forward(self,x):\n",
        "    out = F.relu(self.conv1(x))\n",
        "    out = self.conv2(out)\n",
        "    out = F.relu(self.bn1(out))\n",
        "    out = out.view(-1, nn_input*number_of_filters2)\n",
        "    #out = self.global_mxpool(out)\n",
        "    out = self.fc1(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.fc2(out)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjbDpTHyv3iw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = Net(input_size, hidden_size, num_classes)\n",
        "criterian = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr = learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zUy8o7zrO4Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "56add347-113f-493f-e09c-00dc99c82e02"
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "  for i, (images, labels) in enumerate(train_loader):    \n",
        "    images = Variable(images)\n",
        "    labels = Variable(labels)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(images)\n",
        "    loss = criterian(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if (i+1)%100 == 0:\n",
        "          print('Epoch [%d/%d], Step [%d/%d],Loss: %.4f'\n",
        "                %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size,loss.data))\n",
        "      \n",
        "    "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/20], Step [100/1562],Loss: 1.7464\n",
            "Epoch [1/20], Step [200/1562],Loss: 1.5123\n",
            "Epoch [1/20], Step [300/1562],Loss: 1.5026\n",
            "Epoch [1/20], Step [400/1562],Loss: 1.6257\n",
            "Epoch [1/20], Step [500/1562],Loss: 1.7638\n",
            "Epoch [1/20], Step [600/1562],Loss: 1.1865\n",
            "Epoch [1/20], Step [700/1562],Loss: 1.3594\n",
            "Epoch [1/20], Step [800/1562],Loss: 1.2063\n",
            "Epoch [1/20], Step [900/1562],Loss: 1.4294\n",
            "Epoch [1/20], Step [1000/1562],Loss: 0.9570\n",
            "Epoch [1/20], Step [1100/1562],Loss: 1.6125\n",
            "Epoch [1/20], Step [1200/1562],Loss: 1.2394\n",
            "Epoch [1/20], Step [1300/1562],Loss: 1.2422\n",
            "Epoch [1/20], Step [1400/1562],Loss: 1.2482\n",
            "Epoch [1/20], Step [1500/1562],Loss: 1.2313\n",
            "Epoch [2/20], Step [100/1562],Loss: 1.0685\n",
            "Epoch [2/20], Step [200/1562],Loss: 1.5287\n",
            "Epoch [2/20], Step [300/1562],Loss: 0.7991\n",
            "Epoch [2/20], Step [400/1562],Loss: 1.2158\n",
            "Epoch [2/20], Step [500/1562],Loss: 0.9089\n",
            "Epoch [2/20], Step [600/1562],Loss: 1.5266\n",
            "Epoch [2/20], Step [700/1562],Loss: 0.7760\n",
            "Epoch [2/20], Step [800/1562],Loss: 1.0067\n",
            "Epoch [2/20], Step [900/1562],Loss: 1.2708\n",
            "Epoch [2/20], Step [1000/1562],Loss: 1.3360\n",
            "Epoch [2/20], Step [1100/1562],Loss: 1.0419\n",
            "Epoch [2/20], Step [1200/1562],Loss: 1.0851\n",
            "Epoch [2/20], Step [1300/1562],Loss: 1.4810\n",
            "Epoch [2/20], Step [1400/1562],Loss: 1.1527\n",
            "Epoch [2/20], Step [1500/1562],Loss: 0.9529\n",
            "Epoch [3/20], Step [100/1562],Loss: 0.9192\n",
            "Epoch [3/20], Step [200/1562],Loss: 1.0986\n",
            "Epoch [3/20], Step [300/1562],Loss: 1.1115\n",
            "Epoch [3/20], Step [400/1562],Loss: 0.6325\n",
            "Epoch [3/20], Step [500/1562],Loss: 0.6552\n",
            "Epoch [3/20], Step [600/1562],Loss: 0.9847\n",
            "Epoch [3/20], Step [700/1562],Loss: 0.9061\n",
            "Epoch [3/20], Step [800/1562],Loss: 0.6558\n",
            "Epoch [3/20], Step [900/1562],Loss: 0.7137\n",
            "Epoch [3/20], Step [1000/1562],Loss: 0.7746\n",
            "Epoch [3/20], Step [1100/1562],Loss: 1.0677\n",
            "Epoch [3/20], Step [1200/1562],Loss: 0.9491\n",
            "Epoch [3/20], Step [1300/1562],Loss: 1.1906\n",
            "Epoch [3/20], Step [1400/1562],Loss: 0.7587\n",
            "Epoch [3/20], Step [1500/1562],Loss: 0.9473\n",
            "Epoch [4/20], Step [100/1562],Loss: 0.9561\n",
            "Epoch [4/20], Step [200/1562],Loss: 0.6706\n",
            "Epoch [4/20], Step [300/1562],Loss: 0.7903\n",
            "Epoch [4/20], Step [400/1562],Loss: 0.7922\n",
            "Epoch [4/20], Step [500/1562],Loss: 0.7083\n",
            "Epoch [4/20], Step [600/1562],Loss: 0.7594\n",
            "Epoch [4/20], Step [700/1562],Loss: 1.0262\n",
            "Epoch [4/20], Step [800/1562],Loss: 0.6682\n",
            "Epoch [4/20], Step [900/1562],Loss: 0.6800\n",
            "Epoch [4/20], Step [1000/1562],Loss: 0.8614\n",
            "Epoch [4/20], Step [1100/1562],Loss: 0.6592\n",
            "Epoch [4/20], Step [1200/1562],Loss: 0.8660\n",
            "Epoch [4/20], Step [1300/1562],Loss: 0.8914\n",
            "Epoch [4/20], Step [1400/1562],Loss: 0.8735\n",
            "Epoch [4/20], Step [1500/1562],Loss: 0.8065\n",
            "Epoch [5/20], Step [100/1562],Loss: 0.5338\n",
            "Epoch [5/20], Step [200/1562],Loss: 0.6596\n",
            "Epoch [5/20], Step [300/1562],Loss: 0.7918\n",
            "Epoch [5/20], Step [400/1562],Loss: 0.6852\n",
            "Epoch [5/20], Step [500/1562],Loss: 0.4340\n",
            "Epoch [5/20], Step [600/1562],Loss: 0.8159\n",
            "Epoch [5/20], Step [700/1562],Loss: 0.7475\n",
            "Epoch [5/20], Step [800/1562],Loss: 0.6043\n",
            "Epoch [5/20], Step [900/1562],Loss: 0.6802\n",
            "Epoch [5/20], Step [1000/1562],Loss: 0.7260\n",
            "Epoch [5/20], Step [1100/1562],Loss: 0.7181\n",
            "Epoch [5/20], Step [1200/1562],Loss: 0.6920\n",
            "Epoch [5/20], Step [1300/1562],Loss: 0.7947\n",
            "Epoch [5/20], Step [1400/1562],Loss: 0.6842\n",
            "Epoch [5/20], Step [1500/1562],Loss: 0.5577\n",
            "Epoch [6/20], Step [100/1562],Loss: 0.3628\n",
            "Epoch [6/20], Step [200/1562],Loss: 0.4915\n",
            "Epoch [6/20], Step [300/1562],Loss: 0.8782\n",
            "Epoch [6/20], Step [400/1562],Loss: 0.6319\n",
            "Epoch [6/20], Step [500/1562],Loss: 0.6461\n",
            "Epoch [6/20], Step [600/1562],Loss: 0.6147\n",
            "Epoch [6/20], Step [700/1562],Loss: 0.6087\n",
            "Epoch [6/20], Step [800/1562],Loss: 0.5381\n",
            "Epoch [6/20], Step [900/1562],Loss: 0.6032\n",
            "Epoch [6/20], Step [1000/1562],Loss: 0.6333\n",
            "Epoch [6/20], Step [1100/1562],Loss: 0.5661\n",
            "Epoch [6/20], Step [1200/1562],Loss: 0.5212\n",
            "Epoch [6/20], Step [1300/1562],Loss: 0.5085\n",
            "Epoch [6/20], Step [1400/1562],Loss: 0.8065\n",
            "Epoch [6/20], Step [1500/1562],Loss: 0.6276\n",
            "Epoch [7/20], Step [100/1562],Loss: 0.4746\n",
            "Epoch [7/20], Step [200/1562],Loss: 0.4597\n",
            "Epoch [7/20], Step [300/1562],Loss: 0.3720\n",
            "Epoch [7/20], Step [400/1562],Loss: 0.7206\n",
            "Epoch [7/20], Step [500/1562],Loss: 0.5559\n",
            "Epoch [7/20], Step [600/1562],Loss: 0.6618\n",
            "Epoch [7/20], Step [700/1562],Loss: 0.4908\n",
            "Epoch [7/20], Step [800/1562],Loss: 0.5419\n",
            "Epoch [7/20], Step [900/1562],Loss: 0.3729\n",
            "Epoch [7/20], Step [1000/1562],Loss: 0.6192\n",
            "Epoch [7/20], Step [1100/1562],Loss: 0.7972\n",
            "Epoch [7/20], Step [1200/1562],Loss: 0.5176\n",
            "Epoch [7/20], Step [1300/1562],Loss: 0.5078\n",
            "Epoch [7/20], Step [1400/1562],Loss: 0.5435\n",
            "Epoch [7/20], Step [1500/1562],Loss: 0.4147\n",
            "Epoch [8/20], Step [100/1562],Loss: 0.3788\n",
            "Epoch [8/20], Step [200/1562],Loss: 0.5126\n",
            "Epoch [8/20], Step [300/1562],Loss: 0.5096\n",
            "Epoch [8/20], Step [400/1562],Loss: 0.2338\n",
            "Epoch [8/20], Step [500/1562],Loss: 0.4515\n",
            "Epoch [8/20], Step [600/1562],Loss: 0.4674\n",
            "Epoch [8/20], Step [700/1562],Loss: 0.3564\n",
            "Epoch [8/20], Step [800/1562],Loss: 0.3155\n",
            "Epoch [8/20], Step [900/1562],Loss: 0.3521\n",
            "Epoch [8/20], Step [1000/1562],Loss: 0.3767\n",
            "Epoch [8/20], Step [1100/1562],Loss: 0.3301\n",
            "Epoch [8/20], Step [1200/1562],Loss: 0.3423\n",
            "Epoch [8/20], Step [1300/1562],Loss: 0.3356\n",
            "Epoch [8/20], Step [1400/1562],Loss: 0.7354\n",
            "Epoch [8/20], Step [1500/1562],Loss: 0.3790\n",
            "Epoch [9/20], Step [100/1562],Loss: 0.1777\n",
            "Epoch [9/20], Step [200/1562],Loss: 0.4519\n",
            "Epoch [9/20], Step [300/1562],Loss: 0.2290\n",
            "Epoch [9/20], Step [400/1562],Loss: 0.5200\n",
            "Epoch [9/20], Step [500/1562],Loss: 0.3255\n",
            "Epoch [9/20], Step [600/1562],Loss: 0.4560\n",
            "Epoch [9/20], Step [700/1562],Loss: 0.4900\n",
            "Epoch [9/20], Step [800/1562],Loss: 0.2597\n",
            "Epoch [9/20], Step [900/1562],Loss: 0.3258\n",
            "Epoch [9/20], Step [1000/1562],Loss: 0.4381\n",
            "Epoch [9/20], Step [1100/1562],Loss: 0.5109\n",
            "Epoch [9/20], Step [1200/1562],Loss: 0.4345\n",
            "Epoch [9/20], Step [1300/1562],Loss: 0.6538\n",
            "Epoch [9/20], Step [1400/1562],Loss: 0.4627\n",
            "Epoch [9/20], Step [1500/1562],Loss: 0.3756\n",
            "Epoch [10/20], Step [100/1562],Loss: 0.2652\n",
            "Epoch [10/20], Step [200/1562],Loss: 0.2149\n",
            "Epoch [10/20], Step [300/1562],Loss: 0.2865\n",
            "Epoch [10/20], Step [400/1562],Loss: 0.1723\n",
            "Epoch [10/20], Step [500/1562],Loss: 0.2761\n",
            "Epoch [10/20], Step [600/1562],Loss: 0.2951\n",
            "Epoch [10/20], Step [700/1562],Loss: 0.2742\n",
            "Epoch [10/20], Step [800/1562],Loss: 0.4174\n",
            "Epoch [10/20], Step [900/1562],Loss: 0.6198\n",
            "Epoch [10/20], Step [1000/1562],Loss: 0.3872\n",
            "Epoch [10/20], Step [1100/1562],Loss: 0.3110\n",
            "Epoch [10/20], Step [1200/1562],Loss: 0.2945\n",
            "Epoch [10/20], Step [1300/1562],Loss: 0.2761\n",
            "Epoch [10/20], Step [1400/1562],Loss: 0.2167\n",
            "Epoch [10/20], Step [1500/1562],Loss: 0.3394\n",
            "Epoch [11/20], Step [100/1562],Loss: 0.2667\n",
            "Epoch [11/20], Step [200/1562],Loss: 0.2408\n",
            "Epoch [11/20], Step [300/1562],Loss: 0.2805\n",
            "Epoch [11/20], Step [400/1562],Loss: 0.1861\n",
            "Epoch [11/20], Step [500/1562],Loss: 0.1956\n",
            "Epoch [11/20], Step [600/1562],Loss: 0.0981\n",
            "Epoch [11/20], Step [700/1562],Loss: 0.2874\n",
            "Epoch [11/20], Step [800/1562],Loss: 0.2317\n",
            "Epoch [11/20], Step [900/1562],Loss: 0.2615\n",
            "Epoch [11/20], Step [1000/1562],Loss: 0.2550\n",
            "Epoch [11/20], Step [1100/1562],Loss: 0.1964\n",
            "Epoch [11/20], Step [1200/1562],Loss: 0.2518\n",
            "Epoch [11/20], Step [1300/1562],Loss: 0.2199\n",
            "Epoch [11/20], Step [1400/1562],Loss: 0.2473\n",
            "Epoch [11/20], Step [1500/1562],Loss: 0.1333\n",
            "Epoch [12/20], Step [100/1562],Loss: 0.0834\n",
            "Epoch [12/20], Step [200/1562],Loss: 0.3060\n",
            "Epoch [12/20], Step [300/1562],Loss: 0.2773\n",
            "Epoch [12/20], Step [400/1562],Loss: 0.1330\n",
            "Epoch [12/20], Step [500/1562],Loss: 0.1616\n",
            "Epoch [12/20], Step [600/1562],Loss: 0.1572\n",
            "Epoch [12/20], Step [700/1562],Loss: 0.2157\n",
            "Epoch [12/20], Step [800/1562],Loss: 0.2314\n",
            "Epoch [12/20], Step [900/1562],Loss: 0.0807\n",
            "Epoch [12/20], Step [1000/1562],Loss: 0.2403\n",
            "Epoch [12/20], Step [1100/1562],Loss: 0.1345\n",
            "Epoch [12/20], Step [1200/1562],Loss: 0.2356\n",
            "Epoch [12/20], Step [1300/1562],Loss: 0.3091\n",
            "Epoch [12/20], Step [1400/1562],Loss: 0.2510\n",
            "Epoch [12/20], Step [1500/1562],Loss: 0.2197\n",
            "Epoch [13/20], Step [100/1562],Loss: 0.1412\n",
            "Epoch [13/20], Step [200/1562],Loss: 0.1308\n",
            "Epoch [13/20], Step [300/1562],Loss: 0.0984\n",
            "Epoch [13/20], Step [400/1562],Loss: 0.1299\n",
            "Epoch [13/20], Step [500/1562],Loss: 0.0918\n",
            "Epoch [13/20], Step [600/1562],Loss: 0.0967\n",
            "Epoch [13/20], Step [700/1562],Loss: 0.1585\n",
            "Epoch [13/20], Step [800/1562],Loss: 0.0658\n",
            "Epoch [13/20], Step [900/1562],Loss: 0.1337\n",
            "Epoch [13/20], Step [1000/1562],Loss: 0.1235\n",
            "Epoch [13/20], Step [1100/1562],Loss: 0.2257\n",
            "Epoch [13/20], Step [1200/1562],Loss: 0.1738\n",
            "Epoch [13/20], Step [1300/1562],Loss: 0.2975\n",
            "Epoch [13/20], Step [1400/1562],Loss: 0.1675\n",
            "Epoch [13/20], Step [1500/1562],Loss: 0.2576\n",
            "Epoch [14/20], Step [100/1562],Loss: 0.0848\n",
            "Epoch [14/20], Step [200/1562],Loss: 0.2274\n",
            "Epoch [14/20], Step [300/1562],Loss: 0.0587\n",
            "Epoch [14/20], Step [400/1562],Loss: 0.0303\n",
            "Epoch [14/20], Step [500/1562],Loss: 0.0899\n",
            "Epoch [14/20], Step [600/1562],Loss: 0.1088\n",
            "Epoch [14/20], Step [700/1562],Loss: 0.1576\n",
            "Epoch [14/20], Step [800/1562],Loss: 0.1003\n",
            "Epoch [14/20], Step [900/1562],Loss: 0.0948\n",
            "Epoch [14/20], Step [1000/1562],Loss: 0.1812\n",
            "Epoch [14/20], Step [1100/1562],Loss: 0.1411\n",
            "Epoch [14/20], Step [1200/1562],Loss: 0.2996\n",
            "Epoch [14/20], Step [1300/1562],Loss: 0.1797\n",
            "Epoch [14/20], Step [1400/1562],Loss: 0.2242\n",
            "Epoch [14/20], Step [1500/1562],Loss: 0.1854\n",
            "Epoch [15/20], Step [100/1562],Loss: 0.1081\n",
            "Epoch [15/20], Step [200/1562],Loss: 0.0531\n",
            "Epoch [15/20], Step [300/1562],Loss: 0.0664\n",
            "Epoch [15/20], Step [400/1562],Loss: 0.1028\n",
            "Epoch [15/20], Step [500/1562],Loss: 0.2642\n",
            "Epoch [15/20], Step [600/1562],Loss: 0.1306\n",
            "Epoch [15/20], Step [700/1562],Loss: 0.0366\n",
            "Epoch [15/20], Step [800/1562],Loss: 0.0830\n",
            "Epoch [15/20], Step [900/1562],Loss: 0.0557\n",
            "Epoch [15/20], Step [1000/1562],Loss: 0.1251\n",
            "Epoch [15/20], Step [1100/1562],Loss: 0.1238\n",
            "Epoch [15/20], Step [1200/1562],Loss: 0.0508\n",
            "Epoch [15/20], Step [1300/1562],Loss: 0.0735\n",
            "Epoch [15/20], Step [1400/1562],Loss: 0.0606\n",
            "Epoch [15/20], Step [1500/1562],Loss: 0.0877\n",
            "Epoch [16/20], Step [100/1562],Loss: 0.0317\n",
            "Epoch [16/20], Step [200/1562],Loss: 0.0451\n",
            "Epoch [16/20], Step [300/1562],Loss: 0.0721\n",
            "Epoch [16/20], Step [400/1562],Loss: 0.0639\n",
            "Epoch [16/20], Step [500/1562],Loss: 0.0603\n",
            "Epoch [16/20], Step [600/1562],Loss: 0.0468\n",
            "Epoch [16/20], Step [700/1562],Loss: 0.0693\n",
            "Epoch [16/20], Step [800/1562],Loss: 0.1172\n",
            "Epoch [16/20], Step [900/1562],Loss: 0.0234\n",
            "Epoch [16/20], Step [1000/1562],Loss: 0.0864\n",
            "Epoch [16/20], Step [1100/1562],Loss: 0.0534\n",
            "Epoch [16/20], Step [1200/1562],Loss: 0.0404\n",
            "Epoch [16/20], Step [1300/1562],Loss: 0.0494\n",
            "Epoch [16/20], Step [1400/1562],Loss: 0.1069\n",
            "Epoch [16/20], Step [1500/1562],Loss: 0.1034\n",
            "Epoch [17/20], Step [100/1562],Loss: 0.0942\n",
            "Epoch [17/20], Step [200/1562],Loss: 0.0141\n",
            "Epoch [17/20], Step [300/1562],Loss: 0.0502\n",
            "Epoch [17/20], Step [400/1562],Loss: 0.0397\n",
            "Epoch [17/20], Step [500/1562],Loss: 0.0271\n",
            "Epoch [17/20], Step [600/1562],Loss: 0.0457\n",
            "Epoch [17/20], Step [700/1562],Loss: 0.0881\n",
            "Epoch [17/20], Step [800/1562],Loss: 0.0704\n",
            "Epoch [17/20], Step [900/1562],Loss: 0.0245\n",
            "Epoch [17/20], Step [1000/1562],Loss: 0.1568\n",
            "Epoch [17/20], Step [1100/1562],Loss: 0.0228\n",
            "Epoch [17/20], Step [1200/1562],Loss: 0.0698\n",
            "Epoch [17/20], Step [1300/1562],Loss: 0.1291\n",
            "Epoch [17/20], Step [1400/1562],Loss: 0.0744\n",
            "Epoch [17/20], Step [1500/1562],Loss: 0.1327\n",
            "Epoch [18/20], Step [100/1562],Loss: 0.0199\n",
            "Epoch [18/20], Step [200/1562],Loss: 0.0284\n",
            "Epoch [18/20], Step [300/1562],Loss: 0.0287\n",
            "Epoch [18/20], Step [400/1562],Loss: 0.0325\n",
            "Epoch [18/20], Step [500/1562],Loss: 0.0214\n",
            "Epoch [18/20], Step [600/1562],Loss: 0.0157\n",
            "Epoch [18/20], Step [700/1562],Loss: 0.0176\n",
            "Epoch [18/20], Step [800/1562],Loss: 0.0079\n",
            "Epoch [18/20], Step [900/1562],Loss: 0.0738\n",
            "Epoch [18/20], Step [1000/1562],Loss: 0.0326\n",
            "Epoch [18/20], Step [1100/1562],Loss: 0.0527\n",
            "Epoch [18/20], Step [1200/1562],Loss: 0.0186\n",
            "Epoch [18/20], Step [1300/1562],Loss: 0.0492\n",
            "Epoch [18/20], Step [1400/1562],Loss: 0.1387\n",
            "Epoch [18/20], Step [1500/1562],Loss: 0.0195\n",
            "Epoch [19/20], Step [100/1562],Loss: 0.0153\n",
            "Epoch [19/20], Step [200/1562],Loss: 0.0136\n",
            "Epoch [19/20], Step [300/1562],Loss: 0.0131\n",
            "Epoch [19/20], Step [400/1562],Loss: 0.0450\n",
            "Epoch [19/20], Step [500/1562],Loss: 0.0191\n",
            "Epoch [19/20], Step [600/1562],Loss: 0.0173\n",
            "Epoch [19/20], Step [700/1562],Loss: 0.0341\n",
            "Epoch [19/20], Step [800/1562],Loss: 0.0328\n",
            "Epoch [19/20], Step [900/1562],Loss: 0.0686\n",
            "Epoch [19/20], Step [1000/1562],Loss: 0.0153\n",
            "Epoch [19/20], Step [1100/1562],Loss: 0.0136\n",
            "Epoch [19/20], Step [1200/1562],Loss: 0.0443\n",
            "Epoch [19/20], Step [1300/1562],Loss: 0.0483\n",
            "Epoch [19/20], Step [1400/1562],Loss: 0.0413\n",
            "Epoch [19/20], Step [1500/1562],Loss: 0.0493\n",
            "Epoch [20/20], Step [100/1562],Loss: 0.0128\n",
            "Epoch [20/20], Step [200/1562],Loss: 0.0103\n",
            "Epoch [20/20], Step [300/1562],Loss: 0.0220\n",
            "Epoch [20/20], Step [400/1562],Loss: 0.0094\n",
            "Epoch [20/20], Step [500/1562],Loss: 0.0533\n",
            "Epoch [20/20], Step [600/1562],Loss: 0.0326\n",
            "Epoch [20/20], Step [700/1562],Loss: 0.0188\n",
            "Epoch [20/20], Step [800/1562],Loss: 0.0118\n",
            "Epoch [20/20], Step [900/1562],Loss: 0.0380\n",
            "Epoch [20/20], Step [1000/1562],Loss: 0.0490\n",
            "Epoch [20/20], Step [1100/1562],Loss: 0.0966\n",
            "Epoch [20/20], Step [1200/1562],Loss: 0.0182\n",
            "Epoch [20/20], Step [1300/1562],Loss: 0.0184\n",
            "Epoch [20/20], Step [1400/1562],Loss: 0.0242\n",
            "Epoch [20/20], Step [1500/1562],Loss: 0.0676\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9OQ6DB1urNj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "08a66df8-2a78-4868-d614-3b3b6d94d3db"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "for images, labels in test_loader:\n",
        "    images = Variable(images)    \n",
        "    outputs = net(images)\n",
        "    _, predicted = torch.max(outputs.data, 1) \n",
        "    total += labels.size(0)               \n",
        "    correct += (predicted == labels).sum()\n",
        "    \n",
        "print('Accuracy on 10k test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on 10k test images: 64 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOlIOgXLxY6U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}